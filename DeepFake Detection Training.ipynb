{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0c7fe5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad9ced6",
   "metadata": {},
   "source": [
    "# Frame Extraction from videos"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79e29ba9",
   "metadata": {},
   "source": [
    "def extract_frames_from_video(video_path, output_folder, frame_interval=30):\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get the total frame count and frame rate\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    print(f\"Processing {video_path} - Total frames: {total_frames}, FPS: {fps}\")\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    video_name = os.path.basename(video_path).split('.')[0]\n",
    "    video_output_folder = os.path.join(output_folder, video_name)\n",
    "    if not os.path.exists(video_output_folder):\n",
    "        os.makedirs(video_output_folder)\n",
    "\n",
    "    # Extract frames\n",
    "    count = 0\n",
    "    saved_frames = 0\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Save the frame every frame_interval frames\n",
    "        if count % frame_interval == 0:\n",
    "            frame_name = os.path.join(video_output_folder, f\"frame_{saved_frames:04d}.jpg\")\n",
    "            cv2.imwrite(frame_name, frame)\n",
    "            saved_frames += 1\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    # Release the video capture object\n",
    "    video.release()\n",
    "\n",
    "    print(f\"Frames saved for {video_path}: {saved_frames}\")\n",
    "    \n",
    "# Function to process all videos in a directory\n",
    "def extract_frames_from_directory(input_folder,output_folder,frame_interval=30):\n",
    "    # List all video files in the input directory\n",
    "    video_files = [f for f in os.listdir(input_folder) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "\n",
    "    # Process each video file\n",
    "    for video_file in video_files:\n",
    "        video_path = os.path.join(input_folder, video_file)\n",
    "        extract_frames_from_video(video_path, output_folder, frame_interval)\n",
    "        \n",
    "# Example usage\n",
    "input_folder = r\"C:\\Users\\wiame\\Documents\\RECONNAISSANCE DES FORMES\\PROJET\\Human Activity Recognition - Video Dataset\\Standing Still\" # Folder containing your videos\n",
    "output_folder = r\"C:\\Users\\wiame\\Documents\\RECONNAISSANCE DES FORMES\\PROJET\\REAL\"   # Folder to store extracted frames\n",
    "frame_interval = 15  # Extract one frame every 30 frames (adjust as needed)\n",
    "\n",
    "extract_frames_from_directory(input_folder, output_folder, frame_interval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2382792c",
   "metadata": {},
   "source": [
    "# RESIZE AND SCALE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1febaefd",
   "metadata": {},
   "source": [
    "def resize_replace_and_scale_frames(folder_path, target_size=(224, 224), scale=True):\n",
    "    \"\"\"\n",
    "    Function to resize all frames in the folder, overwrite them with resized frames, and apply scaling.\n",
    "    \n",
    "    Args:\n",
    "    - folder_path (str): Path to the folder containing the original frames.\n",
    "    - target_size (tuple): The target size for resizing frames (default is 224x224).\n",
    "    - scale (bool): Whether to scale the pixel values to [0, 1] (default is True).\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # List all files in the folder\n",
    "    frame_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    # Loop over each frame file\n",
    "    for frame_file in frame_files:\n",
    "        # Construct full file path\n",
    "        frame_path = os.path.join(folder_path, frame_file)\n",
    "        \n",
    "        # Read the frame\n",
    "        frame = cv2.imread(frame_path)\n",
    "        \n",
    "        if frame is not None:\n",
    "            # Resize the frame\n",
    "            resized_frame = cv2.resize(frame, target_size)\n",
    "            \n",
    "            # Apply scaling (normalize pixel values to [0, 1]) if scale=True\n",
    "            if scale:\n",
    "                resized_frame = resized_frame.astype(np.float32) / 255.0  # Scaling to [0, 1]\n",
    "            \n",
    "            # If scaled, convert the values back to uint8 to save the image\n",
    "            if scale:\n",
    "                resized_frame = (resized_frame * 255).astype(np.uint8)\n",
    "            \n",
    "            # Save the resized (and scaled) frame back to the original file path\n",
    "            cv2.imwrite(frame_path, resized_frame)\n",
    "        else:\n",
    "            print(f\"Error reading the frame: {frame_file}\")\n",
    "    \n",
    "    print(\"Resizing, scaling, and replacement complete.\")\n",
    "    \n",
    "folder_path = r\"C:\\Users\\wiame\\Documents\\RECONNAISSANCE DES FORMES\\PROJET\\1 minute funny videos\"  # Path to the folder containing original frames\n",
    "\n",
    "# Call the resize, replace, and scale function\n",
    "resize_replace_and_scale_frames(folder_path, target_size=(224, 224), scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd109c1",
   "metadata": {},
   "source": [
    "# Faces Extraction with MTCNN"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f2d2b30-307b-4f3f-8f3c-3d6dbc3fcde6",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import os\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "main_folder = r\"C:\\Users\\wiame\\Documents\\RECONNAISSANCE DES FORMES\\PROJET\\indians_real\"\n",
    "output_folder = r\"C:\\Users\\wiame\\Documents\\RECONNAISSANCE DES FORMES\\PROJET\\new_FACES\\real_indians\"\n",
    "\n",
    "detector = MTCNN()\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for sequence_name in os.listdir(main_folder):\n",
    "    sequence_path = os.path.join(main_folder, sequence_name)\n",
    "    \n",
    "    if os.path.isdir(sequence_path):  # Check if it's a folder\n",
    "        sequence_output_path = os.path.join(output_folder, sequence_name)\n",
    "        os.makedirs(sequence_output_path, exist_ok=True)\n",
    "\n",
    "        for frame_name in os.listdir(sequence_path):\n",
    "            frame_path = os.path.join(sequence_path, frame_name)\n",
    "            if frame_name.lower().endswith(('.jpg', '.png', '.jpeg')):  # Image files\n",
    "                image = cv2.imread(frame_path)\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Detect faces\n",
    "                results = detector.detect_faces(image_rgb)\n",
    "\n",
    "                for i, result in enumerate(results):\n",
    "                    x, y, width, height = result['box']\n",
    "                    face = image[y:y+height, x:x+width]\n",
    "                    \n",
    "                    # Ensure dimensions are valid\n",
    "                    if face.size > 0:\n",
    "                        # Resize the face to 224x224\n",
    "                        face_resized = cv2.resize(face, (224, 224))\n",
    "                        \n",
    "                        # Save the resized face\n",
    "                        face_path = os.path.join(sequence_output_path, f\"{os.path.splitext(frame_name)[0]}_face_{i}.jpg\")\n",
    "                        cv2.imwrite(face_path, face_resized)\n",
    "\n",
    "print(\"Processing complete. Faces saved to:\", output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a8c9d-845b-4499-ac9a-35954c96bd25",
   "metadata": {},
   "source": [
    "## Delete Noise in faces"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3aa70eb-6d94-4312-9f21-ac55e53b9d64",
   "metadata": {},
   "source": [
    "main_folder = r\"C:\\Users\\wiame\\Documents\\RECONNAISSANCE DES FORMES\\PROJET\\new_FACES\\real_indians\"\n",
    "\n",
    "# Walk through all subfolders in the main folder\n",
    "for root, _, files in os.walk(main_folder):\n",
    "    for filename in files:\n",
    "        # Check if the file does not end with \"_0.jpg\"\n",
    "        if not filename.endswith(\"_0.jpg\"):\n",
    "            file_path = os.path.join(root, filename)\n",
    "            os.remove(file_path)  # Delete the file\n",
    "            print(f\"Deleted: {file_path}\")  # Log deleted files\n",
    "        else:\n",
    "            print(f\"Keeping: {filename}\")  # Log kept files\n",
    "\n",
    "print(\"Cleaning complete. Unwanted files have been deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a11ed3-e543-4cce-b2b8-25c877ff7b7c",
   "metadata": {},
   "source": [
    "## Select half the folders"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee252ef0-fdcb-49e7-847c-6e9d067839c2",
   "metadata": {},
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def select_random_videos(input_folder, output_folder, fraction=0.5):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # List all subfolders in the input folder\n",
    "    subfolders = os.listdir(input_folder)\n",
    "\n",
    "    # Group subfolders by their prefix (e.g., '1_', '2_', ..., '28_')\n",
    "    groups = {}\n",
    "    for subfolder in subfolders:\n",
    "        prefix = subfolder.split('_')[0]  # Get the prefix (e.g., '1', '2', ..., '28')\n",
    "        if prefix not in groups:\n",
    "            groups[prefix] = []\n",
    "        groups[prefix].append(subfolder)\n",
    "\n",
    "    # Process each group (e.g., '1_', '2_', ...)\n",
    "    for prefix, video_folders in groups.items():\n",
    "        # Calculate how many folders to select\n",
    "        num_to_select = int(len(video_folders) * fraction)\n",
    "        \n",
    "        # Randomly select subfolders\n",
    "        selected_folders = random.sample(video_folders, num_to_select)\n",
    "        \n",
    "        # Copy the selected folders to the output folder\n",
    "        for folder in selected_folders:\n",
    "            # Path for the current subfolder in input\n",
    "            subfolder_path = os.path.join(input_folder, folder)\n",
    "            \n",
    "            # Create the corresponding output subfolder path\n",
    "            output_subfolder_path = os.path.join(output_folder, folder)\n",
    "            os.makedirs(output_subfolder_path, exist_ok=True)\n",
    "            \n",
    "            # Copy all files from the subfolder to the output folder\n",
    "            for file_name in os.listdir(subfolder_path):\n",
    "                file_path = os.path.join(subfolder_path, file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    shutil.copy(file_path, output_subfolder_path)\n",
    "\n",
    "            print(f\"Copied {folder} to {output_folder}\")\n",
    "\n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "# Define your input and output folders\n",
    "input_folder = r\"C:\\Users\\wiame\\Documents\\RECONNAISSANCE DES FORMES\\PROJET\\FACES\\FAKE\"\n",
    "output_folder = r\"C:\\Users\\wiame\\Documents\\RECONNAISSANCE DES FORMES\\PROJET\\new_FACES\\FAKE\"\n",
    "\n",
    "# Call the function to select random videos\n",
    "select_random_videos(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4edf84f-f43b-46e3-921c-438444efb6c2",
   "metadata": {},
   "source": [
    "## START RESNET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c7d60aa-a3ba-4731-b9d1-1c07add3369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "# Create a new model for feature extraction (we use the output of the ResNet50 base model)\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=base_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64c5db93-bdce-48bc-8764-634a52a19d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Preprocess a single image frame for ResNet50.\n",
    "    \"\"\"\n",
    "    # Read and resize the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert BGR to RGB (ResNet expects RGB images)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Normalize and preprocess the image (same normalization as ImageNet)\n",
    "    image_preprocessed = preprocess_input(image_rgb)  # Normalization for ResNet\n",
    "\n",
    "    # Expand dimensions to match model input shape (batch size 1)\n",
    "    image_batch = np.expand_dims(image_preprocessed, axis=0)\n",
    "\n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "338ffd75-7acd-4cb0-80a4-bf78b8124163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_for_sequence(sequence_path, model):\n",
    "    \"\"\"\n",
    "    Extract features for all frames in a video sequence folder.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for frame_name in sorted(os.listdir(sequence_path)):  # Ensure frames are ordered\n",
    "        frame_path = os.path.join(sequence_path, frame_name)\n",
    "        if frame_name.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "            # Preprocess the image for ResNet\n",
    "            image_batch = preprocess_image(frame_path)\n",
    "            \n",
    "            # Extract feature vector using ResNet50\n",
    "            feature_vector = model.predict(image_batch, verbose=0)\n",
    "            \n",
    "            # Flatten the feature vector to 1D\n",
    "            features.append(feature_vector.flatten())\n",
    "\n",
    "    return np.array(features)  # Return as NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42e55da2-d1c0-456a-a482-94d33e4683b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features for 1906 sequences.\n",
      "Example sequence shape: (21, 2048)\n",
      "Labels: [1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def label_and_extract_features(base_folder, model):\n",
    "    \"\"\"\n",
    "    Extract features and labels for all video sequences in the dataset.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for label_name, label_value in {'real': 1, 'fake': 0}.items():\n",
    "        folder_path = os.path.join(base_folder, label_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for sequence_name in os.listdir(folder_path):\n",
    "                sequence_path = os.path.join(folder_path, sequence_name)\n",
    "                if os.path.isdir(sequence_path):  # Ensure it's a folder\n",
    "                    # Extract features for this video sequence\n",
    "                    features = extract_features_for_sequence(sequence_path, model)\n",
    "                    data.append(features)  # Store the feature vectors\n",
    "                    labels.append(label_value)  # Store the label for this sequence\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "# Example: Label and extract features for the entire dataset\n",
    "faces_train_folder = r\"C:\\Users\\wiame\\Documents\\RECONNAISSANCE DES FORMES\\PROJET\\new_FACES\"\n",
    "data, labels = label_and_extract_features(faces_train_folder, feature_extractor)\n",
    "\n",
    "# Example: Check shapes\n",
    "print(f\"Extracted features for {len(data)} sequences.\")\n",
    "print(f\"Example sequence shape: {data[0].shape}\")\n",
    "print(f\"Labels: {labels[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3615141f-069f-401f-b012-7a3aa93b55ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1906\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "4f2d9028-60bb-4664-aabf-01187b139566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(data[54].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "673c5eba-7075-4d61-b8b4-6f187f4a3cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched Labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Invert the labels\n",
    "labels_ = labels\n",
    "labels = [1 - label for label in labels]\n",
    "\n",
    "# Check the switched labels\n",
    "print(f\"Switched Labels: {labels[:10]}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbf7971e-13fa-42f8-a582-02b06049302b",
   "metadata": {},
   "source": [
    "print(\"labels: \",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "867886df-07b5-4380-bc83-a8ddf4d2d5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.01019593 0.         ... 0.15548107 0.00454331 0.01489409]\n",
      " [0.         0.0069849  0.03151723 ... 0.6935246  0.04988791 0.04736813]\n",
      " [0.         0.04420053 0.         ... 0.6044611  0.03543784 1.1451368 ]\n",
      " ...\n",
      " [0.         0.         0.01888422 ... 0.52261317 0.14337139 0.2568845 ]\n",
      " [0.         0.         0.00144351 ... 0.6186473  0.05271327 0.07659001]\n",
      " [0.         0.20504765 0.00982271 ... 0.12995012 0.11378016 0.03949445]]\n"
     ]
    }
   ],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "09aeeabf-608c-461e-a847-f451a8b87f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 108\n"
     ]
    }
   ],
   "source": [
    "size_frames = []\n",
    "for sequence in data:\n",
    "    size_frames.append(sequence.shape[0])\n",
    "\n",
    "print(np.min(size_frames), np.max(size_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "75ca4334-706f-4588-9700-cdc7e83fc29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(size_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "81ec6d13-3757-452b-b7b3-2d6e7f917dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "num4 = len(arr[(arr > 0) & (arr<10)])\n",
    "print(num4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8753a326-45fd-47e0-a915-bea2475f3040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of padded data: (1906, 108, 2048)\n",
      "Shape of labels: (1906,)\n"
     ]
    }
   ],
   "source": [
    "# Padding the sequences to ensure they all have the same length\n",
    "max_length = np.max(size_frames) # Set this according to your data (e.g., max number of frames per sequence)\n",
    "data_padded = pad_sequences(data, maxlen=max_length, dtype='float32', padding='post', truncating='post')\n",
    "\n",
    "# Check shapes\n",
    "print(f\"Shape of padded data: {data_padded.shape}\")\n",
    "print(f\"Shape of labels: {labels_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "31cd9061-01dc-4c80-aa65-5ce7c55541ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 108\n"
     ]
    }
   ],
   "source": [
    "size_frames = []\n",
    "for sequence in data_padded:\n",
    "    size_frames.append(sequence.shape[0])\n",
    "\n",
    "print(np.min(size_frames), np.max(size_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "731b3f37-776d-4d98-aa1a-0723e1ee669c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of labels: (1906,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of labels: {labels_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7cf2a2be-7639-4c58-ba5f-03e84aa93db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1906,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data_padded)  # Assuming your data is in a NumPy array\n",
    "Y = np.array(labels)  # Assuming your labels are in a NumPy array\n",
    "print(Y.shape)\n",
    "\n",
    "# Split the data into training and testing sets (e.g., 80% for training and 20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9958f855-cf41-4059-8092-94479041bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_cv, y_test, y_cv = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ae2f955f-9211-4220-87c5-2bd94802ff45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1334, 108, 2048) (1334,)\n",
      "(286, 108, 2048) (286,)\n",
      "(286, 108, 2048) (286,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_cv.shape, y_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b329b358-ac59-459c-83ee-264c93ad21e7",
   "metadata": {},
   "source": [
    "## APPLY LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6919f8be-6d25-42cc-b494-0ed661eaef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a Masking layer to ignore padding values\n",
    "model.add(Masking(mask_value=0.0, input_shape=(max_length, 2048)))  # Mask value is typically 0\n",
    "\n",
    "# Add the LSTM layer\n",
    "model.add(LSTM(64, return_sequences=False))  # 2048 is the feature vector size\n",
    "\n",
    "# Add Dropout for regularization\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Add Dense layer with sigmoid activation for binary classification\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification (real vs fake)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4f79272f-a8d6-427f-8fdd-5481f6a6d65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9910 - loss: 0.0457 - val_accuracy: 0.9685 - val_loss: 0.0981\n",
      "Epoch 2/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 103ms/step - accuracy: 0.9876 - loss: 0.0485 - val_accuracy: 0.9650 - val_loss: 0.1065\n",
      "Epoch 3/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.9646 - loss: 0.1126 - val_accuracy: 0.9720 - val_loss: 0.0925\n",
      "Epoch 4/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - accuracy: 0.9705 - loss: 0.0761 - val_accuracy: 0.9615 - val_loss: 0.1286\n",
      "Epoch 5/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.9840 - loss: 0.0486 - val_accuracy: 0.9336 - val_loss: 0.1969\n",
      "Epoch 6/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.9558 - loss: 0.1150 - val_accuracy: 0.9685 - val_loss: 0.0843\n",
      "Epoch 7/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 105ms/step - accuracy: 0.9853 - loss: 0.0559 - val_accuracy: 0.9650 - val_loss: 0.0991\n",
      "Epoch 8/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 94ms/step - accuracy: 0.9905 - loss: 0.0336 - val_accuracy: 0.9685 - val_loss: 0.1053\n",
      "Epoch 9/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.9975 - loss: 0.0180 - val_accuracy: 0.9685 - val_loss: 0.0995\n",
      "Epoch 10/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 98ms/step - accuracy: 0.9637 - loss: 0.1031 - val_accuracy: 0.9755 - val_loss: 0.0897\n",
      "Epoch 11/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9994 - loss: 0.0262 - val_accuracy: 0.9510 - val_loss: 0.1476\n",
      "Epoch 12/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.9954 - loss: 0.0232 - val_accuracy: 0.9685 - val_loss: 0.1056\n",
      "Epoch 13/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.9928 - loss: 0.0227 - val_accuracy: 0.9720 - val_loss: 0.0821\n",
      "Epoch 14/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9998 - loss: 0.0092 - val_accuracy: 0.9720 - val_loss: 0.0981\n",
      "Epoch 15/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9995 - loss: 0.0076 - val_accuracy: 0.9615 - val_loss: 0.0982\n",
      "Epoch 16/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9685 - val_loss: 0.1052\n",
      "Epoch 17/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 96ms/step - accuracy: 0.9989 - loss: 0.0080 - val_accuracy: 0.9685 - val_loss: 0.1140\n",
      "Epoch 18/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.9974 - loss: 0.0150 - val_accuracy: 0.9441 - val_loss: 0.2099\n",
      "Epoch 19/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.9804 - loss: 0.0463 - val_accuracy: 0.9650 - val_loss: 0.1052\n",
      "Epoch 20/20\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.9944 - loss: 0.0243 - val_accuracy: 0.9685 - val_loss: 0.1075\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20, \n",
    "    batch_size=32,\n",
    "    validation_data=(X_cv, y_cv),  # Cross-validation\n",
    "    verbose=1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ff212115-1f8f-4926-a152-ac2250930301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9715 - loss: 0.1247\n",
      "Test Loss: 0.11215542256832123\n",
      "Test Accuracy: 0.9720279574394226\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ffebd396-4f53-4c7b-b62e-2e439224e748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Get predictions from the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to binary (0 or 1)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "eb7a7b06-7896-49e1-9529-2dea2bc89aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
